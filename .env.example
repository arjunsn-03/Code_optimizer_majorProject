# ── Ollama ────────────────────────────────────────────────────────────────────
OLLAMA_HOST=http://localhost:11434
DEFAULT_MODEL=qwen3:8b        # qwen3:8b | llama3 | mistral

# ── Embeddings ────────────────────────────────────────────────────────────────
EMBED_MODEL=all-MiniLM-L6-v2

# ── Energy ────────────────────────────────────────────────────────────────────
GRID_INTENSITY=0.475          # kg CO₂e / kWh  (world avg)
CPU_TDP_WATTS=15              # adjust for your CPU (e.g. 65 for desktop)

# ── Profiler ─────────────────────────────────────────────────────────────────
WARMUP_RUNS=2
BENCH_RUNS=5

# ── Pipeline ──────────────────────────────────────────────────────────────────
MAX_PATCH_RISK=0.7
TOP_N_HOTSPOTS=5
TEST_TIMEOUT_SECS=120
